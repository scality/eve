#!/usr/bin/env python
# coding: utf-8
"""Eve configuration file for buildbot.

This module is the core source code of eve.
It is in fact the configuration file for buildbot.
See the `Buildbot Manual`_ for more informations.

.. _Buildbot Manual:
    http://docs.buildbot.net/latest/manual/index.html
"""

import socket
import string
import time
from collections import OrderedDict
from fnmatch import fnmatch
from functools import wraps
from os import environ, path
from random import choice, randint
from tempfile import mktemp, mkdtemp

import yaml
from buildbot.changes.gitpoller import GitPoller
from buildbot.config import BuilderConfig
from buildbot.locks import MasterLock
from buildbot.plugins import steps
from buildbot.plugins import schedulers
from buildbot.process import buildrequest
from buildbot.process.buildstep import BuildStep
from buildbot.process.factory import BuildFactory
from buildbot.process.properties import Interpolate, Property
from buildbot.process.results import (
    CANCELLED, FAILURE, SUCCESS, SKIPPED, WARNINGS)
from buildbot.steps.http import HTTPStep
from buildbot.steps.master import MasterShellCommand, SetProperty
from buildbot.steps.shell import ShellCommand, SetPropertyFromCommand
from buildbot.steps.source.git import Git
from buildbot.steps.transfer import FileUpload
from buildbot.steps.trigger import Trigger
from buildbot.worker.local import LocalWorker
from buildbot.worker.protocols.pb import Connection
from reporters.base import BitbucketBuildStatusPush
from requests.auth import HTTPBasicAuth
from twisted.internet import defer
from twisted.logger import Logger
from twisted.python.reflect import namedModule

from sentry import init_sentry_logging
from steps.artifacts import Upload, CloudfilesAuthenticate
from steps.docker import DockerBuild
from wamp import get_wamp_conf
from workers import docker, openstack

MASTER_NAME = environ.pop('MASTER_NAME', 'master')

##########################
# Constants
##########################
BOOTSTRAP_BUILDER_NAME = 'bootstrap'
BOOTSTRAP_SCHEDULER_NAME = 'bootstrap-scheduler'
DOCKER_BUILDER_NAME = 'docker-%s' % MASTER_NAME
DOCKER_SCHEDULER_NAME = 'docker-scheduler-%s' % MASTER_NAME
OPENSTACK_BUILDER_NAME = 'openstack-%s' % MASTER_NAME
OPENSTACK_SCHEDULER_NAME = 'openstack-scheduler-%s' % MASTER_NAME
MAX_LOCAL_WORKERS = int(environ.get('MAX_LOCAL_WORKERS', 8))
MAX_DOCKER_WORKERS = MAX_LOCAL_WORKERS * 12
MAX_OPENSTACK_WORKERS = MAX_LOCAL_WORKERS * 10
EVE_FOLDER = 'eve'
EVE_MAIN_YAML = 'main.yml'
EVE_MAIN_YAML_FULL_PATH = '%s/%s' % (EVE_FOLDER, EVE_MAIN_YAML)
EVE_GIT_POLLING = False

OPENSTACK_IDENTITY_URL = 'https://identity.api.rackspacecloud.com/v2.0/'
OPENSTACK_REGION = environ.get('OPENSTACK_REGION', 'DFW')
OPENSTACK_TENANT = 984990
OPENSTACK_SSH_KEY = path.expanduser(
    environ.get('OPENSTACK_SSH_KEY', '~/.ssh/id_rsa'))
OPENSTACK_KEY_NAME = environ.get('OPENSTACK_KEY_NAME', 'eve-key-pair')

CLEANUP_DOCKER_DATE = environ.get("CLEANUP_DOCKER_DATE")
if CLEANUP_DOCKER_DATE:
    CLEANUP_DOCKER_DATE_HOUR, CLEANUP_DOCKER_DATE_MINUTE = \
        map(int, CLEANUP_DOCKER_DATE.split(":"))

CLEANUP_DOCKER_RETENTION = int(environ.get(
    "CLEANUP_DOCKER_RETENTION", "86400"
))

SCRIPTS_DIRPATH = path.join(path.dirname(__file__), "scripts")
DATA_DIRPATH = path.join(path.dirname(__file__), "data")

##########################
# Set/Check environment variables
##########################

# store 'secret' environment variables in a separate dictionary
SECRETS = {}

for skey in dict(environ):
    if skey.startswith('SECRET_'):
        SECRETS[skey.lstrip('SECRET_')] = environ.pop(skey)

# git
GIT_REPO = environ.pop('GIT_REPO')
LOCAL_GIT_REPO = environ.pop('LOCAL_GIT_REPO', GIT_REPO)
GIT_REPO_SHORT = GIT_REPO.split('/')[-1].replace('.git', '')
GIT_CACHE_DIR_HOST = mkdtemp(prefix=GIT_REPO_SHORT)

GIT_KEY_PATH = environ.pop('GIT_KEY_PATH')

# Sentry
SENTRY_DSN = environ.pop('SENTRY_DSN', None)

# docker

EXTERNAL_URL = environ.pop('EXTERNAL_URL')
MASTER_FQDN = environ.pop('MASTER_FQDN')
WORKER_SUFFIX = environ.pop('WORKER_SUFFIX')

DOCKER_CERT_PATH = environ.get('DOCKER_CERT_PATH', None)
DOCKER_TLS_VERIFY = environ.get('DOCKER_TLS_VERIFY', '0')
if DOCKER_TLS_VERIFY != '0':
    # Checking that docker env vars are coherent
    assert path.isfile(path.join(DOCKER_CERT_PATH, 'ca.pem'))
    assert path.isfile(path.join(DOCKER_CERT_PATH, 'key.pem'))
    assert path.isfile(path.join(DOCKER_CERT_PATH, 'cert.pem'))

# bitbucket
EVE_BITBUCKET_LOGIN = environ.pop('EVE_BITBUCKET_LOGIN')
EVE_BITBUCKET_PWD = environ.pop('EVE_BITBUCKET_PWD')

BITBUCKET_PUB_KEY = environ.get('BITBUCKET_PUB_KEY', None)

OAUTH2_CLIENT_ID = environ.pop('OAUTH2_CLIENT_ID')
OAUTH2_CLIENT_SECRET = environ.pop('OAUTH2_CLIENT_SECRET')

PROJECT_NAME = environ.pop('PROJECT_NAME')
PROJECT_URL = environ.pop('PROJECT_URL')

TRY_PWD = environ.pop('TRY_PWD')

# database
DB_URL = environ.pop('DB_URL', 'sqlite:///state.sqlite')

RAX_LOGIN = environ.pop('RAX_LOGIN', None)
RAX_PWD = environ.pop('RAX_PWD', None)

# artifacts
CLOUDFILES_URL = environ.pop(
    'CLOUDFILES_URL',
    'https://storage101.dfw1.clouddrive.com/v1/MossoCloudFS_984990/')
ARTIFACTS_URL = environ.pop(
    'ARTIFACTS_URL',
    'https://artifacts.devsca.com/builds')

ARTIFACTS_PREFIX = environ.get(
    'ARTIFACTS_PREFIX',
    'staging-')

Upload.CLOUDFILES_URL = CLOUDFILES_URL
Upload.ARTIFACTS_URL = ARTIFACTS_URL
Upload.ARTIFACTS_PREFIX = ARTIFACTS_PREFIX

MASTER_START_TIME = time.time()


##########################
# Project Identity
##########################
EVE_CONF = BuildmasterConfig = OrderedDict()  # pylint: disable=invalid-name
EVE_CONF['title'] = "the %s project" % PROJECT_NAME
EVE_CONF['titleURL'] = PROJECT_URL
EVE_CONF['buildbotURL'] = EXTERNAL_URL

##########################
# Multi Master
##########################
WAMP_ROUTER_URL = environ.pop('WAMP_ROUTER_URL')
WAMP_REALM = environ.pop('WAMP_REALM')
EVE_CONF['multiMaster'] = True
EVE_CONF['mq'] = get_wamp_conf(WAMP_ROUTER_URL, WAMP_REALM)

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that
# workers could connect to your master with this protocol.
# 'port' must match the value configured into the buildworkers (with their
# --master option)
EVE_CONF['protocols'] = {'pb': {'port': 'tcp:%s:interface=%s' % (
    environ['PB_PORT'], socket.gethostbyname(MASTER_FQDN))}}

# DB URL
EVE_CONF['db'] = {
    'db_url': DB_URL,
}

###########################
# Misc.
###########################

EVE_CONF['buildbotNetUsageData'] = None

# #########################
# Reporters
# #########################
# Reporters send the build status when finished

EVE_CONF['services'] = []

# To reactivate when fixed
# EVE_CONF['services'].append(HipChatBuildStatusPush(
#    builders=[BOOTSTRAP_BUILDER_NAME]))

EVE_CONF['services'].append(BitbucketBuildStatusPush(
    builders=[DOCKER_BUILDER_NAME, OPENSTACK_BUILDER_NAME]))

##########################
# ArtifactUpload
##########################


class ShellCommandWithSecrets(ShellCommand):
    """ Execute a shell command that needs secret environment variables.

    All variables on the form SECRET_{var} will be passed as {var} inside the
    worker. Naturally, the environment is not logged during such a step.

    """

    def __init__(self, *args, **kwargs):
        new_env = kwargs.pop('env', {})
        new_env.update(SECRETS)

        kwargs.update({
            'logEnviron': False,
            'env': new_env,
        })

        super(ShellCommandWithSecrets, self).__init__(*args, **kwargs)


##########################
# Workers
##########################
EVE_CONF['workers'] = []


def password_generator(size=18, chars=string.ascii_uppercase + string.digits):
    return ''.join(choice(chars) for _ in range(size))

# Create MAX_LOCAL_WORKERS Local Workers that will bootstrap all the jobs
LOCAL_WORKERS = []
for i in range(MAX_LOCAL_WORKERS):
    LOCAL_WORKERS.append(LocalWorker('lw%03d-%s' % (i, WORKER_SUFFIX)))
EVE_CONF['workers'].extend(LOCAL_WORKERS)


# Then create MAX_DOCKER_WORKERS Docker Workers that will do the real job
DOCKER_WORKERS = []
for i in range(MAX_DOCKER_WORKERS):
    DOCKER_WORKERS.append(
        docker.EveDockerLatentWorker(
            name='dw%03d-%s' % (i, WORKER_SUFFIX),
            password=password_generator(),
            master_fqdn=MASTER_FQDN,
            image=Property('docker_image'),
            keepalive_interval=300,
        ))
EVE_CONF['workers'].extend(DOCKER_WORKERS)


# Create MAX_OPENSTACK_WORKERS that will do the vm job
OPENSTACK_WORKERS = []
for i in range(MAX_OPENSTACK_WORKERS):
    OPENSTACK_WORKERS.append(
        openstack.EveOpenStackLatentWorker(
            name='ow%03d-%s' % (i, WORKER_SUFFIX),
            password=password_generator(),
            image=Property('openstack_image'),
            flavor=Property('openstack_flavor'),
            block_devices=None,
            os_auth_url=OPENSTACK_IDENTITY_URL,
            os_tenant_name=OPENSTACK_TENANT,
            os_username=RAX_LOGIN,
            os_password=RAX_PWD,
            region=OPENSTACK_REGION,
            git_key_path=GIT_KEY_PATH,
            bitbucket_pub_key=BITBUCKET_PUB_KEY,
            ssh_key=OPENSTACK_SSH_KEY,
            meta=None,
            masterFQDN=MASTER_FQDN,
            nova_args=dict(key_name=OPENSTACK_KEY_NAME),
            build_wait_timeout=0,  # do not reuse the instance
            keepalive_interval=300,
            client_version='2'))
EVE_CONF['workers'].extend(OPENSTACK_WORKERS)

##########################
# Change Sources
##########################
# the 'change_source' setting tells the buildmaster how it should find out
# about source code changes.

EVE_CONF['change_source'] = []
if EVE_GIT_POLLING:
    EVE_CONF['change_source'].append(GitPoller(
        GIT_REPO,
        workdir='gitpoller-workdir',
        branches=True,
        pollinterval=900,
        pollAtLaunch=False,
        buildPushesWithNoCommits=True,
    ))


##########################
# Custom Build Steps
##########################
class ReadConfFromYaml(FileUpload):
    """Load the YAML file to `conf` property.

    This step Reads the YAML file and converts it to a `conf` property which
    is made available to the following steps.
    """
    logger = Logger('eve.steps.ReadConfFromYaml')

    def __init__(self, **kwargs):
        self.masterdest = mktemp()
        FileUpload.__init__(
            self,
            name='read %s' % EVE_MAIN_YAML_FULL_PATH,
            workersrc=EVE_MAIN_YAML_FULL_PATH,
            masterdest=self.masterdest,
            haltOnFailure=True,
            hideStepIf=lambda results, s: results == SUCCESS,
            **kwargs)

    @defer.inlineCallbacks
    def run(self):
        result = yield FileUpload.run(self)
        if result != SUCCESS:
            self.addCompleteLog('stderr', 'Could not find %s' %
                                EVE_MAIN_YAML_FULL_PATH)
            defer.returnValue(result)

        raw_conf = open(self.masterdest).read()
        self.addCompleteLog(EVE_MAIN_YAML_FULL_PATH, raw_conf)
        conf = yaml.load(raw_conf)
        # Expand entries with several branch patterns
        try:
            branches = conf['branches']
        except (TypeError, KeyError):
            self.addCompleteLog('stderr', 'Could not find the branches field'
                                          'in %s' % EVE_MAIN_YAML_FULL_PATH)
            defer.returnValue(FAILURE)

        new_branches = {}
        for branch_patterns, branch_conf in branches.items():
            for branch_pattern in branch_patterns.split(','):
                new_branches[branch_pattern.strip()] = branch_conf
        conf['branches'] = new_branches
        self.setProperty('conf', conf, "ReadConfFromYaml")
        self.setProperty('master_start_time', MASTER_START_TIME)

        # Find the stage name from the branch name
        branch = self.getProperty('branch')
        if branch is None:
            branch = 'default'
        for branch_pattern, branch_conf in conf['branches'].items():
            self.logger.debug('Checking if <{branch}> matches <{pattern}>',
                              branch=branch, pattern=branch_pattern)
            if fnmatch(branch, branch_pattern):
                stage_name = branch_conf['stage']
                self.logger.debug('<{branch}> matched <{branch_pattern}>',
                                  branch=branch, branch_pattern=branch_pattern)
                break
        else:
            self.logger.debug('No branch match. Using default branch config.')
            try:
                stage_name = conf['branches']['default']['stage']
            except KeyError:
                self.addCompleteLog(
                    'stderr', 'Branch <%s> not covered by yaml file' % branch)
                defer.returnValue(CANCELLED)

        self.setProperty('stage_name', stage_name, 'ReadConfFromYaml Step')

        self.build.addStepsAfterCurrentStep([
            TriggerStages([
                stage_name
            ], waitForFinish=True, haltOnFailure=True)
        ])
        defer.returnValue(SUCCESS)


class CancelCommand(MasterShellCommand):
    """Cancel a build according to result of command."""

    def processEnded(self, status_object):
        """If the return code is non-zero set build to CANCELLED."""
        if status_object.value.exitCode != 0:
            self.finished(CANCELLED)
        else:
            super(CancelCommand, self).processEnded(status_object)


class CancelNonTipBuild(CancelCommand):
    """Cancel if the current revision is not the tip of the branch."""

    def __init__(self, **kwargs):
        super(CancelNonTipBuild, self).__init__(
            name='check if build is relevant',
            command=Interpolate('[ "%(prop:revision)s" = "" ]'
                                '|| [ "$(git rev-list -1 %(prop:branch)s)"'
                                ' = "%(prop:revision)s" ]'),
            hideStepIf=lambda results, s: results == SUCCESS,
            workdir=GIT_CACHE_DIR_HOST,
        )


class CancelOldBuild(CancelCommand):
    """Cancel if the build is previous buildbot instance."""

    def __init__(self, **kwargs):
        super(CancelOldBuild, self).__init__(
            name='prevent unuseful restarts',
            hideStepIf=lambda results, s: results == SUCCESS,
            command=Interpolate('[ "' + str(MASTER_START_TIME) +
                                '" = "%(prop:master_start_time)s" ]'),
        )


class StepExtractor(BuildStep):
    """Extracts and adds the build steps to the current builder.

    This step extracts the build steps from the `conf` property and adds them
    to the current builder. It also adds a step to build an image.
    """
    name = 'step extractor'
    logger = Logger('eve.steps.StepExtractor')

    def run(self):
        conf = self.getProperty('conf')
        stage_name = self.getProperty('stage_name')
        stage_conf = conf['stages'][stage_name]
        for step in stage_conf['steps']:
            step_type, params = next(step.iteritems())
            try:
                # try to see if the required step is imported or
                # defined in the current context
                _cls = globals()[step_type]
            except KeyError:
                # otherwise import the step from standars buildbot steps
                try:
                    _cls = getattr(steps, step_type)
                except AttributeError:
                    raise Exception('Could not load step %s' % step_type)

            # Replace the %(prop:*)s in the text with an Interpolate obj
            params = replace_with_interpolate(params)

            if issubclass(_cls, Git):
                # retry 10 times if git step fails, wait 60s between retries
                params['retry'] = (60, 10)

            if issubclass(_cls, Upload):
                # retry 5 times if upload step fails, wait 60s between retries
                params['retry'] = (60, 5)

            # hack to avoid putting clear passwords into the YAML file
            # for the HTTP step
            if issubclass(_cls, HTTPStep):
                pwd = params['auth'][1].replace('$', '')
                if pwd in environ:
                    params['auth'] = HTTPBasicAuth(
                        params['auth'][0], environ[pwd])

            # Hack! Buildbot does not accept unicode step names
            if 'name' in params and isinstance(params['name'], unicode):
                params['name'] = params['name'].encode('utf-8')

            step = _cls(**params)
            self.build.addStepsAfterLastStep([step])
            self.logger.debug('Add {step} with params : {params}',
                              step=step_type, params=params)
        return defer.succeed(SUCCESS)


class TriggerStages(BuildStep):
    """Start a list of stages."""

    def __init__(self, stage_names, **kwargs_for_exec_trigger_stages):
        self.stage_names = stage_names

        kwargs_for_exec_trigger_stages.setdefault("waitForFinish", True)
        self._kwargs_for_exec_trigger_stages = kwargs_for_exec_trigger_stages

        kwargs = {
            'name': 'prepare {0} stage(s)'.format(len(self.stage_names)),
            'hideStepIf': lambda results, s: results == SUCCESS,
            'haltOnFailure': True,
        }
        super(TriggerStages, self).__init__(**kwargs)

    @defer.inlineCallbacks
    def run(self):
        conf = self.getProperty('conf')

        preliminary_steps = OrderedDict()
        build_orders = []

        for stage_name in self.stage_names:
            stage = conf['stages'][stage_name]
            worker = stage['worker']

            worker_type_to_class = {
                'docker': DockerBuildOrder,
                'openstack': OpenStackBuildOrder
            }
            build_order_class = worker_type_to_class.get(worker['type'])

            if build_order_class is None:
                defer.returnValue(FAILURE)

            build_order = build_order_class(
                stage_name, stage, worker, self
            )

            def set_property(result, propname):
                build_order.properties[propname] = result

            setprop_defers = []
            for propname, propvalue in build_order.properties.iteritems():
                setprop_defer = self.build.render(propvalue)
                setprop_defer.addCallback(set_property, propname)
                setprop_defers.append(setprop_defer)

            yield defer.gatherResults(setprop_defers)
            build_orders.append(build_order)

            for step in build_order.preliminary_steps:
                preliminary_steps[step] = ''

        self.build.addStepsAfterCurrentStep([
            ExecuteTriggerStages(
                build_orders, **self._kwargs_for_exec_trigger_stages
            )
        ])
        self.build.addStepsAfterCurrentStep(list(preliminary_steps))

        defer.returnValue(SUCCESS)


class BaseBuildOrder(object):
    """Base class representing a build to trigger
    (Scheduler and properties)
    """
    scheduler = None

    def __init__(self, stage_name, stage, worker, parent_step):
        self._stage_name = stage_name
        self._stage = stage
        self._worker = worker
        self._parent_step = parent_step

        self.properties = {}
        self.preliminary_steps = []

        self.setup_properties()

    def setup_properties(self):
        """
        Setup additional properties
        :return: None
        """
        properties = self._parent_step.getProperties()
        self.properties = {
            k: v[0] for k, v in properties.asDict().iteritems()
        }
        self.properties.update({
            'stage_name': self._stage_name,
            'reason': self._stage_name,
            'git_reference': GIT_REPO,
            'git_repo': GIT_REPO,
        })


class DockerBuildOrder(BaseBuildOrder):
    """Base class representing a build to trigger on a Docker container
    (Scheduler, properties and docker config)
    """
    scheduler = DOCKER_SCHEDULER_NAME

    def setup_properties(self):
        super(DockerBuildOrder, self).setup_properties()

        self.properties['docker_volumes'] = self._worker.get('volumes', []) + [
            '{0}:{0}'.format('/var/run/docker.sock')
        ]

        self.properties['worker_path'] = self._worker.get('path')
        if self.properties['worker_path'] is None:
            self.properties['docker_image'] = Interpolate(
                self._worker['image'])
            return

        full_docker_path = '%s/build/%s' % (
            self.properties['master_builddir'],
            self.properties['worker_path'],
        )
        self.properties['docker_image'] = '%s-%06d' % (
            self.properties['worker_path'],
            self.properties['buildnumber'],
        )

        self.preliminary_steps.append(DockerBuild(
            image=self.properties['docker_image'],
            dockerfile=self._worker.get("dockerfile"),
            workdir=full_docker_path,
            name='build docker image from %s' % self.properties['worker_path'],
            flunkOnFailure=False,
            haltOnFailure=False
        ))

        # Workaround EVE-215
        # The previous docker build could fail because:
        # - the dockerfile is incorrect
        # - the remote sources are unavailable
        # - or we hit EVE-215, and the previous image in cache
        #   is not reliable
        # In all cases, try again once and ignore cached images (nocache)
        self.preliminary_steps.append(DockerBuild(
            image=self.properties['docker_image'],
            dockerfile=self._worker.get("dockerfile"),
            workdir=full_docker_path,
            name='docker build retry from %s' % self.properties['worker_path'],
            hideStepIf=lambda results, s: results == SKIPPED,
            is_retry=True,
            doStepIf=lambda step: step.build.getProperties()
            .getProperty('DockerBuildFailed', '') == step.image
        ))
        # end of workaround


class OpenStackBuildOrder(BaseBuildOrder):
    """Base class representing a build to trigger on an OpenStack instance
    (Scheduler, properties and OpenStack config)
    """
    scheduler = OPENSTACK_SCHEDULER_NAME

    DEFAULT_IMAGE = 'Ubuntu 14.04 LTS (Trusty Tahr) (PVHVM)'
    DEFAULT_FLAVOR = 'general1-4'
    """See https://developer.rackspace.com/docs/cloud-servers/v2/general-api-info/flavors/."""

    def setup_properties(self):
        super(OpenStackBuildOrder, self).setup_properties()

        self.properties.update({
            'worker_path': self._worker['path'],
            'openstack_image': self._worker.get('image', self.DEFAULT_IMAGE),
            'openstack_flavor': self._worker.get('flavor', self.DEFAULT_FLAVOR)
        })


class ExecuteTriggerStages(Trigger):
    """Execute simultaneously multiple build steps.

    It's a fake Trigger stage which run multiple BuildStep simultaneously.
    """

    def __init__(self, build_orders, *args, **kwargs):
        kwargs.update({
            "schedulerNames": ["foo"]
        })
        super(ExecuteTriggerStages, self).__init__(*args, **kwargs)

        self._build_orders = build_orders

    def getSchedulersAndProperties(self):
        return [{
            'sched_name': build_order.scheduler,
            'props_to_set': build_order.properties,
            'unimportant': False
        } for build_order in self._build_orders]


# #########################
# Bootstrap Sequence: Build step factory
# #########################
BOOTSTRAP_FACTORY = BuildFactory()
if RAX_LOGIN:
    BOOTSTRAP_FACTORY.addStep(
        CloudfilesAuthenticate(rax_login=RAX_LOGIN, rax_pwd=RAX_PWD))

# Check out the source
GIT_CACHE_UPDATE_LOCK = MasterLock("git_cache_update")
BOOTSTRAP_FACTORY.addStep(
    ShellCommand(name='update git repo cache',
                 workdir=GIT_CACHE_DIR_HOST,
                 command=(
                     'git clone --mirror --recursive %s . || '
                     'git remote update' % LOCAL_GIT_REPO),
                 locks=[GIT_CACHE_UPDATE_LOCK.access('exclusive')],
                 hideStepIf=lambda results, s: results == SUCCESS,
                 haltOnFailure=True))

BOOTSTRAP_FACTORY.addStep(CancelNonTipBuild())

BOOTSTRAP_FACTORY.addStep(
    SetPropertyFromCommand(
        name='get the git sha1 from the branch name',
        command=Interpolate('cd ' + GIT_CACHE_DIR_HOST +
                            ' && git rev-list -1 %(prop:branch)s'),
        hideStepIf=lambda results, s: results == SUCCESS,
        property='revision'))

BOOTSTRAP_FACTORY.addStep(
    SetProperty(
        name='setting the master_builddir property',
        property='master_builddir',
        hideStepIf=lambda results, s: results == SUCCESS,
        value=Property('builddir')))

BOOTSTRAP_FACTORY.addStep(
    Git(name='checkout git branch',
        repourl=GIT_CACHE_DIR_HOST,
        shallow=True,
        retry=(60, 10),
        submodules=True,
        mode='incremental',
        hideStepIf=lambda results, s: results == SUCCESS,
        haltOnFailure=True))
# Read conf from yaml file
BOOTSTRAP_FACTORY.addStep(ReadConfFromYaml())

# #########################
# Bootstrap Sequence: Builders
# #########################
EVE_CONF['builders'] = []
EVE_CONF['builders'].append(
    BuilderConfig(
        name=BOOTSTRAP_BUILDER_NAME,
        workernames=[lw.name for lw in LOCAL_WORKERS],
        factory=BOOTSTRAP_FACTORY,
        properties={
            'artifacts_url': ARTIFACTS_URL,
            'artifacts_prefix': ARTIFACTS_PREFIX,
        },
    )
)

# #########################
# Triggerable Sequence: Schedulers
# #########################
EVE_CONF['schedulers'] = []

EVE_CONF['schedulers'].append(schedulers.Triggerable(
    name=DOCKER_SCHEDULER_NAME,
    builderNames=[DOCKER_BUILDER_NAME]))

EVE_CONF['schedulers'].append(schedulers.Triggerable(
    name=OPENSTACK_SCHEDULER_NAME,
    builderNames=[OPENSTACK_BUILDER_NAME]))

# #########################
# Triggerable Sequence: Builders
# #########################
for _builder, workers in (
        (DOCKER_BUILDER_NAME, DOCKER_WORKERS),
        (OPENSTACK_BUILDER_NAME, OPENSTACK_WORKERS)):
    factory = BuildFactory()
    factory.addStep(CancelOldBuild())
    # Extract steps from conf
    factory.addStep(StepExtractor(
        name='extract steps from yaml',
        hideStepIf=lambda results, s: results == SUCCESS)
    )

    EVE_CONF['builders'].append(
        BuilderConfig(
            name=_builder,
            workernames=[w.name for w in workers],
            factory=factory,
            collapseRequests=False,
        )
    )

# ########################
# Cleanup Docker hosts job
# ########################

if CLEANUP_DOCKER_DATE:
    CLEANUP_DOCKER_BUILDER_NAME = 'cleanup-docker-{0}'.format(MASTER_NAME)
    CLEANUP_DOCKER_SCHEDULER_NAME = \
        'cleanup-docker-scheduler-{0}'.format(MASTER_NAME)

    CLEANUP_DOCKER_FACTORY = BuildFactory()
    CLEANUP_DOCKER_FACTORY.addStep(
        ShellCommand(
            name='run the Docker cleanup script',
            command=[
                "./cleanup_docker.sh",
                "--retention", str(CLEANUP_DOCKER_RETENTION),
                "--keep-image-file", path.join(
                    DATA_DIRPATH, "docker_images.list"
                ),
                "--keep-container-file", path.join(
                    DATA_DIRPATH, "docker_containers.list"
                ),
            ],
            workdir=SCRIPTS_DIRPATH,
            decodeRC={
                0: SUCCESS,
                2: WARNINGS,
            },
            warnOnWarnings=True,
        )
    )

    CLEANUP_DOCKER_BUILDER = BuilderConfig(
        name=CLEANUP_DOCKER_BUILDER_NAME,
        workernames=[local_worker.name for local_worker in LOCAL_WORKERS],
        factory=CLEANUP_DOCKER_FACTORY,
        collapseRequests=True,
        description='clean old Docker containers and images',
    )
    EVE_CONF['builders'].append(CLEANUP_DOCKER_BUILDER)

    CLEANUP_DOCKER_SCHEDULER = schedulers.Nightly(
        name=CLEANUP_DOCKER_SCHEDULER_NAME,
        builderNames=[CLEANUP_DOCKER_BUILDER_NAME],
        hour=CLEANUP_DOCKER_DATE_HOUR,
        minute=CLEANUP_DOCKER_DATE_MINUTE,
    )
    EVE_CONF['schedulers'].append(CLEANUP_DOCKER_SCHEDULER)

# #########################
# Collapsing requests
# #########################
EVE_CONF['collapseRequests'] = False

# #########################
# Hacks/Bugfixes
# #########################

# Hack to allow build step name interpolation
from buildbot.process.buildstep import BuildStep


def hide_interpolatable_name(func):
    """Hide the interpolatable name to be later rendered."""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        self._interpolatable_name = kwargs.pop('name', None) or self.name
        self.name = str(self._interpolatable_name)
        return func(self, *args, **kwargs)
    return wrapper


def render_interpolatable_name(func):
    """Render the hidden interpolatable name before proceeding."""
    @wraps(func)
    @defer.inlineCallbacks
    def wrapper(self, *args, **kwargs):
        if isinstance(self._interpolatable_name, Interpolate):
            d = self.build.render(self._interpolatable_name)

            def set_name(res):
                self.name = res
            d.addCallback(set_name)
            yield d
        res = yield func(self, *args, **kwargs)
        defer.returnValue(res)
    return wrapper

BuildStep.__init__ = hide_interpolatable_name(BuildStep.__init__)
BuildStep.startStep = render_interpolatable_name(BuildStep.startStep)


# Hack to not restart a worker substantiating on failure
import buildbot.process.build
buildbot.process.build.RETRY = FAILURE

# Hack to fix a bug stating that LocalWorkers do not have a valid path_module
for w in EVE_CONF['workers']:
    w.path_module = namedModule("posixpath")


# Compressed logs generate a lot of issues like this :
# 2016-08-28 14:17:22+0000 [-] /root/eve/workspaces/ring/venv/local/lib/
# python2.7/site-packages/sqlalchemy/engine/default.py:451:
# _mysql_exceptions.Warning: Invalid utf8 character string: 'DAC554'
# This hack fixes them by disabling log compression
EVE_CONF['logCompressionMethod'] = 'raw'


class TempSourceStamp(object):
    """ This is a Hack to fix a bug where the git diff is sent as an str
    instead of unicode and triggers an exception
    """

    def asDict(self):  # pylint: disable=invalid-name,missing-docstring
        result = vars(self).copy()
        del result['ssid']
        del result['changes']
        if 'patch' in result and result['patch'] is None:
            result['patch'] = (None, None, None)
        result['patch_level'], result['patch_body'], result[
            'patch_subdir'] = result.pop('patch')
        result['patch_author'], result[
            'patch_comment'] = result.pop('patch_info')
        assert all(
            isinstance(val, (str, unicode, type(None), int))  # added str here
            for attr, val in result.items()
        ), result
        return result

buildrequest.TempSourceStamp = TempSourceStamp


# #########################
# Sentry Logging
# #########################

SENTRY_DSN = environ.pop('SENTRY_DSN', None)
if SENTRY_DSN:
    init_sentry_logging(SENTRY_DSN)


def replace_with_interpolate(obj):
    """Interpolate nested %(prop:obj)s in step arguments.

    Read step arguments from the yaml file and replaces them with
    interpolate objects when relevant so they can be replaced with
    properties when run.
    """

    if isinstance(obj, dict):
        return {k: replace_with_interpolate(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [replace_with_interpolate(elem) for elem in obj]
    elif isinstance(obj, basestring) and 'prop:' in obj:
        return Interpolate(obj)
    else:
        return obj
