#!/usr/bin/env python
# coding: utf-8
"""Eve configuration file for buildbot.

This module is the core source code of eve.
It is in fact the configuration file for buildbot.
See the `Buildbot Manual`_ for more informations.

.. _Buildbot Manual:
    http://docs.buildbot.net/latest/manual/index.html
"""

import socket
import string
import time
from collections import OrderedDict
from fnmatch import fnmatch
from functool import wraps
from os import environ, path
from random import choice, randint
from tempfile import mktemp

import yaml
from buildbot.changes.gitpoller import GitPoller
from buildbot.config import BuilderConfig
from buildbot.locks import MasterLock
from buildbot.plugins import steps
from buildbot.process import buildrequest
from buildbot.process.buildstep import BuildStep
from buildbot.process.factory import BuildFactory
from buildbot.process.properties import Interpolate, Property
from buildbot.process.results import (CANCELLED, FAILURE, SUCCESS)
from buildbot.schedulers.triggerable import Triggerable
from buildbot.steps.http import HTTPStep
from buildbot.steps.master import MasterShellCommand, SetProperty
from buildbot.steps.shell import ShellCommand
from buildbot.steps.source.git import Git
from buildbot.steps.transfer import FileUpload
from buildbot.steps.trigger import Trigger
from buildbot.worker.local import LocalWorker
from buildbot.worker.protocols.pb import Connection
from requests.auth import HTTPBasicAuth
from twisted.internet import defer
from twisted.logger import Logger
from twisted.python.reflect import namedModule

from sentry import init_sentry_logging
from steps.artifacts import Upload, CloudfilesAuthenticate
from wamp import get_wamp_conf
from workers import docker, openstack

# Monkey patch to recover quickly when the
Connection.keepalive_interval = 300

MASTER_NAME = environ.pop('MASTER_NAME', 'master')

##########################
# Constants
##########################
BOOTSTRAP_BUILDER_NAME = 'bootstrap'
BOOTSTRAP_SCHEDULER_NAME = 'bootstrap-scheduler'
DOCKER_BUILDER_NAME = 'docker-%s' % MASTER_NAME
DOCKER_SCHEDULER_NAME = 'docker-scheduler-%s' % MASTER_NAME
OPENSTACK_BUILDER_NAME = 'openstack-%s' % MASTER_NAME
OPENSTACK_SCHEDULER_NAME = 'openstack-scheduler-%s' % MASTER_NAME
MAX_LOCAL_WORKERS = int(environ.get('MAX_LOCAL_WORKERS', 8))
MAX_DOCKER_WORKERS = MAX_LOCAL_WORKERS * 12
MAX_OPENSTACK_WORKERS = MAX_LOCAL_WORKERS * 10
EVE_FOLDER = 'eve'
EVE_MAIN_YAML = 'main.yml'
EVE_MAIN_YAML_FULL_PATH = '%s/%s' % (EVE_FOLDER, EVE_MAIN_YAML)
EVE_GIT_POLLING = False

OPENSTACK_IDENTITY_URL = 'https://identity.api.rackspacecloud.com/v2.0/'
OPENSTACK_REGION = environ.get('OPENSTACK_REGION', 'DFW')
OPENSTACK_TENANT = 984990
OPENSTACK_SSH_KEY = path.expanduser(
    environ.get('OPENSTACK_SSH_KEY', '~/.ssh/id_rsa'))
OPENSTACK_KEY_NAME = environ.get('OPENSTACK_KEY_NAME', 'eve-key-pair')


##########################
# Set/Check environment variables
##########################

# store 'secret' environment variables in a separate dictionary
SECRETS = {}

for skey in dict(environ):
    if skey.startswith('SECRET_'):
        SECRETS[skey.lstrip('SECRET_')] = environ.pop(skey)

# git
GIT_REPO = environ.pop('GIT_REPO')
GIT_REPO_SHORT = GIT_REPO.split('/')[-1].replace('.git', '')
GIT_CACHE_DIR_HOST = '/tmp/' + GIT_REPO_SHORT

GIT_KEY_PATH = environ.pop('GIT_KEY_PATH')
assert path.isfile(GIT_KEY_PATH), (
    'Did not find git RSA cert in %s' % GIT_KEY_PATH)
assert path.isfile(GIT_KEY_PATH + '.pub'), (
    'Did not find public git RSA cert in %s.pub' % GIT_KEY_PATH)

# Sentry
SENTRY_DSN = environ.pop('SENTRY_DSN', None)

# docker

EXTERNAL_URL = environ.pop('EXTERNAL_URL')
MASTER_FQDN = environ.pop('MASTER_FQDN')
WORKER_SUFFIX = environ.pop('WORKER_SUFFIX')

DOCKER_HOST = environ.pop('DOCKER_HOST', 'unix:///var/run/docker.sock')
DOCKER_CERT_PATH = environ.pop('DOCKER_CERT_PATH', None)
DOCKER_TLS_VERIFY = environ.pop('DOCKER_TLS_VERIFY', None)
if DOCKER_CERT_PATH and path.isdir(DOCKER_CERT_PATH):
    DOCKER_CERT_PATH_CA = path.join(DOCKER_CERT_PATH, 'ca.pem')
    DOCKER_CERT_PATH_KEY = path.join(DOCKER_CERT_PATH, 'key.pem')
    DOCKER_CERT_PATH_CERT = path.join(DOCKER_CERT_PATH, 'cert.pem')
    assert path.isfile(DOCKER_CERT_PATH_CA), DOCKER_CERT_PATH_CA
    assert path.isfile(DOCKER_CERT_PATH_KEY), DOCKER_CERT_PATH_KEY
    assert path.isfile(DOCKER_CERT_PATH_CERT), DOCKER_CERT_PATH_CERT

# bitbucket
EVE_BITBUCKET_LOGIN = environ.pop('EVE_BITBUCKET_LOGIN')
EVE_BITBUCKET_PWD = environ.pop('EVE_BITBUCKET_PWD')

BITBUCKET_PUB_KEY = environ.get('BITBUCKET_PUB_KEY', None)

OAUTH2_CLIENT_ID = environ.pop('OAUTH2_CLIENT_ID')
OAUTH2_CLIENT_SECRET = environ.pop('OAUTH2_CLIENT_SECRET')

PROJECT_NAME = environ.pop('PROJECT_NAME')
PROJECT_URL = environ.pop('PROJECT_URL')

TRY_PWD = environ.pop('TRY_PWD')

# database
DB_URL = environ.pop('DB_URL', 'sqlite:///state.sqlite')

RAX_LOGIN = environ.pop('RAX_LOGIN', None)
RAX_PWD = environ.pop('RAX_PWD', None)

# artifacts
CLOUDFILES_URL = environ.pop(
    'CLOUDFILES_URL',
    'https://storage101.dfw1.clouddrive.com/v1/MossoCloudFS_984990/')
ARTIFACTS_URL = environ.pop(
    'ARTIFACTS_URL',
    'https://artifacts.devsca.com/builds')

ARTIFACTS_PREFIX = environ.get(
    'ARTIFACTS_PREFIX',
    'staging-')

Upload.CLOUDFILES_URL = CLOUDFILES_URL
Upload.ARTIFACTS_URL = ARTIFACTS_URL
Upload.ARTIFACTS_PREFIX = ARTIFACTS_PREFIX

ARTIFACTS_LOGIN = environ.pop('ARTIFACTS_LOGIN', None)
ARTIFACTS_PWD = environ.pop('ARTIFACTS_PWD', None)

MASTER_START_TIME = time.time()


##########################
# Project Identity
##########################
EVE_CONF = BuildmasterConfig = OrderedDict()  # pylint: disable=invalid-name
EVE_CONF['title'] = "the %s project" % PROJECT_NAME
EVE_CONF['titleURL'] = PROJECT_URL
EVE_CONF['buildbotURL'] = EXTERNAL_URL

##########################
# Multi Master
##########################
WAMP_ROUTER_URL = environ.pop('WAMP_ROUTER_URL')
WAMP_REALM = environ.pop('WAMP_REALM')
EVE_CONF['multiMaster'] = True
EVE_CONF['mq'] = get_wamp_conf(WAMP_ROUTER_URL, WAMP_REALM)

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that
# workers could connect to your master with this protocol.
# 'port' must match the value configured into the buildworkers (with their
# --master option)
EVE_CONF['protocols'] = {'pb': {'port': 'tcp:%s:interface=%s' % (environ['PB_PORT'], socket.gethostbyname(MASTER_FQDN))}}

# DB URL
EVE_CONF['db'] = {
    'db_url': DB_URL,
}

###########################
# Misc.
###########################

EVE_CONF['buildbotNetUsageData'] = None


##########################
# ArtifactUpload
##########################


class ShellCommandWithSecrets(ShellCommand):
    """ Execute a shell command that needs secret environment variables.

    All variables on the form SECRET_{var} will be passed as {var} inside the
    worker. Naturally, the environment is not logged during such a step.

    """

    def __init__(self, workdir=None, command=None, usePTY=None, **kwargs):
        kwargs['logEnviron'] = False
        kwargs['env'] = {}
        kwargs['env'].update(environ)
        kwargs['env'].update(SECRETS)
        ShellCommand.__init__(self, workdir, command, usePTY, **kwargs)


##########################
# Workers
##########################
EVE_CONF['workers'] = []


def password_generator(size=18, chars=string.ascii_uppercase + string.digits):
    return ''.join(choice(chars) for _ in range(size))

# Create MAX_LOCAL_WORKERS Local Workers that will bootstrap all the jobs
LOCAL_WORKERS = []
for i in range(MAX_LOCAL_WORKERS):
    LOCAL_WORKERS.append(LocalWorker('lw%03d-%s' % (i, WORKER_SUFFIX)))
EVE_CONF['workers'].extend(LOCAL_WORKERS)


# Then create MAX_DOCKER_WORKERS Docker Workers that will do the real job
DOCKER_WORKERS = []
for i in range(MAX_DOCKER_WORKERS):
    DOCKER_WORKERS.append(
        docker.EveDockerLatentWorker(
            name='dw%03d-%s' % (i, WORKER_SUFFIX),
            password=password_generator(),
            docker_host=DOCKER_HOST,
            docker_cert_path=DOCKER_CERT_PATH,
            docker_tls_verify=DOCKER_TLS_VERIFY,
            hostconfig={},
            image=Property('docker_image'),
            followStartupLogs=True,
            keepalive_interval=300,
            masterFQDN=MASTER_FQDN))
EVE_CONF['workers'].extend(DOCKER_WORKERS)


# Create MAX_OPENSTACK_WORKERS that will do the vm job
OPENSTACK_WORKERS = []
for i in range(MAX_OPENSTACK_WORKERS):
    OPENSTACK_WORKERS.append(
        openstack.EveOpenStackLatentWorker(
            name='ow%03d-%s' % (i, WORKER_SUFFIX),
            password=password_generator(),
            image=Property('openstack_image'),
            flavor=Property('openstack_flavor'),
            block_devices=None,
            os_auth_url=OPENSTACK_IDENTITY_URL,
            os_tenant_name=OPENSTACK_TENANT,
            os_username=RAX_LOGIN,
            os_password=RAX_PWD,
            region=OPENSTACK_REGION,
            git_key_path=GIT_KEY_PATH,
            bitbucket_pub_key=BITBUCKET_PUB_KEY,
            ssh_key=OPENSTACK_SSH_KEY,
            meta=None,
            masterFQDN=MASTER_FQDN,
            nova_args=dict(key_name=OPENSTACK_KEY_NAME),
            build_wait_timeout=0,  # do not reuse the instance
            keepalive_interval=300,
            client_version='2'))
EVE_CONF['workers'].extend(OPENSTACK_WORKERS)

##########################
# Change Sources
##########################
# the 'change_source' setting tells the buildmaster how it should find out
# about source code changes.

EVE_CONF['change_source'] = []
if EVE_GIT_POLLING:
    EVE_CONF['change_source'].append(GitPoller(
        GIT_REPO,
        workdir='gitpoller-workdir',
        branches=True,
        pollinterval=900,
        pollAtLaunch=False,
        buildPushesWithNoCommits=True,
    ))


##########################
# Custom Build Steps
##########################
class ReadConfFromYaml(FileUpload):
    """Load the YAML file to `conf` property.

    This step Reads the YAML file and converts it to a `conf` property which
    is made available to the following steps.
    """
    logger = Logger('eve.steps.ReadConfFromYaml')

    def __init__(self, **kwargs):
        self.masterdest = mktemp()
        FileUpload.__init__(
            self,
            name='read %s' % EVE_MAIN_YAML_FULL_PATH,
            workersrc=EVE_MAIN_YAML_FULL_PATH,
            masterdest=self.masterdest,
            haltOnFailure=True,
            **kwargs)

    @defer.inlineCallbacks
    def run(self):
        result = yield FileUpload.run(self)
        if result != SUCCESS:
            self.addCompleteLog('stderr', 'Could not find %s' %
                                EVE_MAIN_YAML_FULL_PATH)
            defer.returnValue(result)

        raw_conf = open(self.masterdest).read()
        self.addCompleteLog(EVE_MAIN_YAML_FULL_PATH, raw_conf)
        conf = yaml.load(raw_conf)
        # Expand entries with several branch patterns
        try:
            branches = conf['branches']
        except (TypeError, KeyError):
            self.addCompleteLog('stderr', 'Could not find the branches field'
                                          'in %s' % EVE_MAIN_YAML_FULL_PATH)
            defer.returnValue(FAILURE)

        new_branches = {}
        for branch_patterns, branch_conf in branches.items():
            for branch_pattern in branch_patterns.split(','):
                new_branches[branch_pattern.strip()] = branch_conf
        conf['branches'] = new_branches
        self.setProperty('conf', conf, "ReadConfFromYaml")
        self.setProperty('master_start_time', MASTER_START_TIME)

        # Find the stage name from the branch name
        branch = self.getProperty('branch')
        if branch is None:
            branch = 'default'
        for branch_pattern, branch_conf in conf['branches'].items():
            self.logger.debug('Checking if <{branch}> matches <{pattern}>',
                              branch=branch, pattern=branch_pattern)
            if fnmatch(branch, branch_pattern):
                stage_name = branch_conf['stage']
                self.logger.debug('<{branch}> matched <{branch_pattern}>',
                                  branch=branch, branch_pattern=branch_pattern)
                break
        else:
            self.logger.debug('No branch match. Using default branch config.')
            try:
                stage_name = conf['branches']['default']['stage']
            except KeyError:
                self.addCompleteLog(
                    'stderr', 'Branch <%s> not covered by yaml file' % branch)
                defer.returnValue(CANCELLED)

        self.setProperty('stage_name', stage_name, 'ReadConfFromYaml Step')

        self.build.addStepsAfterCurrentStep([
            TriggerStages([stage_name], haltOnFailure=True)])
        defer.returnValue(SUCCESS)


class CancelCommand(MasterShellCommand):
    """Cancel a build according to result of command."""

    def processEnded(self, status_object):
        """If the return code is non-zero set build to CANCELLED."""
        if status_object.value.exitCode != 0:
            self.finished(CANCELLED)
        else:
            super(CancelCommand, self).processEnded(status_object)


class CancelNonTipBuild(CancelCommand):
    """Cancel if the current revision is not the tip of the branch."""

    def __init__(self, **kwargs):
        super(CancelNonTipBuild, self).__init__(
            name='check if build is relevant',
            command=Interpolate('[ "$(git rev-list -1 %(prop:branch)s)" = '
                                '"%(prop:revision)s" ]'),
            workdir=GIT_CACHE_DIR_HOST,
        )


class CancelOldBuild(CancelCommand):
    """Cancel if the build is previous buildbot instance."""

    def __init__(self, **kwargs):
        super(CancelOldBuild, self).__init__(
            name='prevent unuseful restarts',
            command=Interpolate('[ "' + str(MASTER_START_TIME) +
                                '" = "%(prop:master_start_time)s" ]'),
        )


class StepExtractor(BuildStep):
    """Extracts and adds the build steps to the current builder.

    This step extracts the build steps from the `conf` property and adds them
    to the current builder. It also adds a step to build an image.
    """
    name = 'step extractor'
    logger = Logger('eve.steps.StepExtractor')

    def run(self):
        conf = self.getProperty('conf')
        stage_name = self.getProperty('stage_name')
        stage_conf = conf['stages'][stage_name]
        for step in stage_conf['steps']:
            step_type, params = next(step.iteritems())
            try:
                # try to see if the required step is imported or
                # defined in the current context
                _cls = globals()[step_type]
            except KeyError:
                # otherwise import the step from standars buildbot steps
                try:
                    _cls = getattr(steps, step_type)
                except AttributeError:
                    raise Exception('Could not load step %s' % step_type)

            # Replace the %(prop:*)s in the text with an Interpolate obj
            params = replace_with_interpolate(params)

            if issubclass(_cls, Git):
                # retry 10 times if git step fails, wait 60s between retries
                params['retry'] = (60, 10)

            if issubclass(_cls, Upload):
                # retry 5 times if upload step fails, wait 60s between retries
                params['retry'] = (60, 5)

            # hack to avoid putting clear passwords into the YAML file
            # for the HTTP step
            if issubclass(_cls, HTTPStep):
                pwd = params['auth'][1].replace('$', '')
                if pwd in environ:
                    params['auth'] = HTTPBasicAuth(
                        params['auth'][0], environ[pwd])

            # Hack! Buildbot does not accept unicode step names
            if 'name' in params and isinstance(params['name'], unicode):
                params['name'] = params['name'].encode('utf-8')

            step = _cls(**params)
            self.build.addStepsAfterLastStep([step])
            self.logger.debug('Add {step} with params : {params}',
                              step=step_type, params=params)
        return defer.succeed(SUCCESS)


class TriggerStages(BuildStep):
    """Start a list of stages."""

    def __init__(self, stage_names, **kwargs):
        self.stage_names = stage_names
        BuildStep.__init__(self, haltOnFailure=True)
        self.kwargs = kwargs
        if 'waitForFinish' not in kwargs:
            kwargs['waitForFinish'] = True
        self.name = 'prepare %d stage(s)' % len(stage_names)

    def run(self):
        conf = self.getProperty('conf')
        preliminary_steps = []
        build_orders = []

        for stage_name in reversed(self.stage_names):
            worker_type = conf['stages'][stage_name]['worker']['type']
            assert worker_type in ('docker', 'openstack')
            if worker_type == 'docker':
                build_order = DockerBuildOrder(stage_name, conf, self)
            elif worker_type == 'openstack':
                # pylint bug 710
                # pylint: disable=redefined-variable-type
                build_order = OpenStackBuildOrder(stage_name, conf, self)
            else:
                return defer.succeed(FAILURE)
            build_orders.append(build_order)
            preliminary_steps.extend(build_order.preliminary_steps)

        self.build.addStepsAfterCurrentStep(
            [ExecuteTriggerStages(build_orders, **self.kwargs)])
        self.build.addStepsAfterCurrentStep(preliminary_steps)

        return defer.succeed(SUCCESS)


class BaseBuildOrder(object):  # pylint:disable=too-few-public-methods
    """Base class representing a build to trigger
    (Scheduler and properties)
    """
    scheduler = None

    def __init__(self, stage_name, conf, parent_step):
        self._stage = conf['stages'][stage_name]
        self._worker = self._stage['worker']
        self._parent_step = parent_step
        self.properties = dict((key, value) for key, value, origin in
                               parent_step.getProperties().asList())
        self.properties['stage_name'] = stage_name
        self.properties['reason'] = stage_name
        self.properties['git_reference'] = GIT_REPO + '.git'
        self.properties['git_repo'] = GIT_REPO
        self.preliminary_steps = []
        self.setup_properties()

    def setup_properties(self):
        """
        Setup additional properties
        :return: None
        """
        raise NotImplementedError()

# pylint: disable=too-few-public-methods


class DockerBuildOrder(BaseBuildOrder):
    """Base class representing a build to trigger on a Docker container
    (Scheduler, properties and docker config)
    """
    scheduler = DOCKER_SCHEDULER_NAME
    docker_build_lock = MasterLock("docker_build")

    def setup_properties(self):
        docker_path = self._worker['path']
        full_docker_path = '%s/build/%s' % (
            self.properties['master_builddir'], docker_path)
        self.properties['worker_path'] = docker_path
        self.properties['docker_volumes'] = self._worker.get('volumes', [])
        self.properties['docker_volumes'].append(
            '%s:%s' % ('/var/run/docker.sock', '/var/run/docker.sock'))

        self.properties['docker_volumes'].append(
            '%s:/root/.ssh/id_rsa:ro' % GIT_KEY_PATH)
        self.properties['docker_volumes'].append(
            '%s:/root/.ssh/id_rsa.pub:ro' % (GIT_KEY_PATH + '.pub'))

        self.properties['docker_image'] = '%s-%06d' % (docker_path,
                                                       randint(0, 999999))

        if DOCKER_TLS_VERIFY == '1':
            docker_cmd = 'docker --tlsverify --host=%s ' \
                         '--tlscacert=%s/ca.pem ' \
                         '--tlscert=%s/cert.pem ' \
                         '--tlskey=%s/key.pem ' \
                         'build' % ( DOCKER_HOST,
                                     DOCKER_CERT_PATH,
                                     DOCKER_CERT_PATH,
                                     DOCKER_CERT_PATH)
        else:
            docker_cmd = 'docker build'

        self.preliminary_steps.append(MasterShellCommand(
            name=str('build docker image from %s' % docker_path),
            command='%s -t %s .' % (docker_cmd,
                                    self.properties['docker_image']),
            workdir=full_docker_path,
            locks=[self.docker_build_lock.access('exclusive')],
        ))


class OpenStackBuildOrder(BaseBuildOrder):
    """Base class representing a build to trigger on an OpenStack instance
    (Scheduler, properties and OpenStack config)
    """
    scheduler = OPENSTACK_SCHEDULER_NAME

    def setup_properties(self):
        self.properties['worker_path'] = self._worker['path']
        self.properties['openstack_image'] = self._worker.get(
            'image', 'Ubuntu 14.04 LTS (Trusty Tahr) (PVHVM)')
        # https://developer.rackspace.com/docs/cloud-servers/v2/general-api-info/flavors/
        self.properties['openstack_flavor'] = self._worker.get(
            'flavor', 'general1-4')


class ExecuteTriggerStages(Trigger):
    """Allows to give specific parameter to every scheduler.

    This is a step that allows to start with the properties specified in the
    schedulerNames argument (tuple) instead of using the properties given in
    the set_properties/copy_properties parameters.
    """

    def __init__(self, build_orders, **kwargs):
        self._build_orders = build_orders
        if 'name' not in kwargs:
            kwargs['name'] = 'trigger %d stage(s)' % len(build_orders)
        Trigger.__init__(self, schedulerNames=['dummy'], **kwargs)

    def getSchedulersAndProperties(self):   # NOQA flake8 to ignore camelCase
        return [(build_order.scheduler, build_order.properties)
                for build_order in self._build_orders]


# #########################
# Bootstrap Sequence: Build step factory
# #########################
BOOTSTRAP_FACTORY = BuildFactory()
if RAX_LOGIN:
    BOOTSTRAP_FACTORY.addStep(
        CloudfilesAuthenticate(rax_login=RAX_LOGIN, rax_pwd=RAX_PWD))

# Check out the source
GIT_CACHE_UPDATE_LOCK = MasterLock("git_cache_update")
BOOTSTRAP_FACTORY.addStep(
    ShellCommand(name='update git repo cache',
                 workdir=GIT_CACHE_DIR_HOST,
                 command=(
                     'git clone --mirror --recursive %s . || '
                     'git remote update' % GIT_REPO),
                 locks=[GIT_CACHE_UPDATE_LOCK.access('exclusive')],
                 haltOnFailure=True))

BOOTSTRAP_FACTORY.addStep(CancelNonTipBuild())

BOOTSTRAP_FACTORY.addStep(
    SetProperty(
        name='setting the master_builddir property',
        property='master_builddir',
        value=Property('builddir')))

BOOTSTRAP_FACTORY.addStep(
    Git(name='checkout git branch',
        repourl=GIT_CACHE_DIR_HOST,
        shallow=True,
        retry=(60, 10),
        submodules=True,
        mode='incremental',
        haltOnFailure=True))
# Read conf from yaml file
BOOTSTRAP_FACTORY.addStep(ReadConfFromYaml())

# #########################
# Bootstrap Sequence: Builders
# #########################
EVE_CONF['builders'] = []
EVE_CONF['builders'].append(
    BuilderConfig(
        name=BOOTSTRAP_BUILDER_NAME,
        workernames=[lw.name for lw in LOCAL_WORKERS],
        factory=BOOTSTRAP_FACTORY))

# #########################
# Triggerable Sequence: Schedulers
# #########################
EVE_CONF['schedulers'] = []

EVE_CONF['schedulers'].append(Triggerable(
    name=DOCKER_SCHEDULER_NAME,
    builderNames=[DOCKER_BUILDER_NAME]))

EVE_CONF['schedulers'].append(Triggerable(
    name=OPENSTACK_SCHEDULER_NAME,
    builderNames=[OPENSTACK_BUILDER_NAME]))

# #########################
# Triggerable Sequence: Builders
# #########################
for _builder, workers in (
        (DOCKER_BUILDER_NAME, DOCKER_WORKERS),
        (OPENSTACK_BUILDER_NAME, OPENSTACK_WORKERS)):
    factory = BuildFactory()
    factory.addStep(CancelOldBuild())
    # Extract steps from conf
    factory.addStep(StepExtractor(name='extract steps from yaml'))
    EVE_CONF['builders'].append(
        BuilderConfig(
            name=_builder,
            workernames=[w.name for w in workers],
            factory=factory,
            collapseRequests=False,
        ))

# #########################
# Collapsing requests
# #########################
EVE_CONF['collapseRequests'] = False

# #########################
# Hacks/Bugfixes
# #########################

# Hack to allow build step name interpolation
from buildbot.process.buildstep import BuildStep

def hide_interpolatable_name(func):
    """Hide the interpolatable name to be later rendered."""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        self._interpolatable_name = kwargs.pop('name', None) or self.name
        self.name = str(self._interpolatable_name)
        return func(self, *args, **kwargs)
    return wrapper

def render_interpolatable_name(func):
    """Render the hidden interpolatable name before proceeding."""
    @wraps(func)
    @defer.inlineCallbacks
    def wrapper(self, *args, **kwargs):
        if isinstance(self._interpolatable_name, Interpolate):
            d = self.build.render(self._interpolatable_name)
            def set_name(res):
                self.name = res
            d.addCallback(set_name)
            yield d
        res = yield func(self, *args, **kwargs)
        defer.returnValue(res)
    return wrapper

BuildStep.__init__ = hide_interpolatable_name(BuildStep.__init__)
BuildStep.startStep = render_interpolatable_name(BuildStep.startStep)


# Hack to not restart a worker substantiating on failure
import buildbot.process.build
buildbot.process.build.RETRY = buildbot.process.build.FAILURE

# Hack to fix a bug stating that LocalWorkers do not have a valid path_module
for w in EVE_CONF['workers']:
    w.path_module = namedModule("posixpath")


# Compressed logs generate a lot of issues like this :
# 2016-08-28 14:17:22+0000 [-] /root/eve/workspaces/ring/venv/local/lib/
# python2.7/site-packages/sqlalchemy/engine/default.py:451:
# _mysql_exceptions.Warning: Invalid utf8 character string: 'DAC554'
# This hack fixes them by disabling log compression
EVE_CONF['logCompressionMethod'] = 'raw'


class TempSourceStamp(object):  # pylint: disable=too-few-public-methods
    """ This is a Hack to fix a bug where the git diff is sent as an str
    instead of unicode and triggers an exception
    """

    def asDict(self):  # pylint: disable=invalid-name,missing-docstring
        result = vars(self).copy()
        del result['ssid']
        del result['changes']
        if 'patch' in result and result['patch'] is None:
            result['patch'] = (None, None, None)
        result['patch_level'], result['patch_body'], result[
            'patch_subdir'] = result.pop('patch')
        result['patch_author'], result[
            'patch_comment'] = result.pop('patch_info')
        assert all(
            isinstance(val, (str, unicode, type(None), int))  # added str here
            for attr, val in result.items()
        ), result
        return result

buildrequest.TempSourceStamp = TempSourceStamp


# #########################
# Sentry Logging
# #########################

SENTRY_DSN = environ.pop('SENTRY_DSN', None)
if SENTRY_DSN:
    init_sentry_logging(SENTRY_DSN)


def replace_with_interpolate(obj):
    """Interpolate nested %(prop:obj)s in step arguments.

    Read step arguments from the yaml file and replaces them with
    interpolate objects when relevant so they can be replaced with
    properties when run.
    """

    if isinstance(obj, dict):
        return {k: replace_with_interpolate(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [replace_with_interpolate(elem) for elem in obj]
    elif isinstance(obj, basestring) and 'prop:' in obj:
        return Interpolate(obj)
    else:
        return obj
